{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Selection Advanced House Price Prediction##\n",
        "\n",
        "The main aim of this project is to predict the house price based on various features which we will discuss as we go ahead\n",
        "\n",
        "Dataset to downloaded from the below link\n",
        "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
        "\n"
      ],
      "metadata": {
        "id": "D91ZqqIRv7F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "## for feature slection\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# to visualise al the columns in the dataframe\n",
        "pd.pandas.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "D3tzY7bpwA-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('/content/EDA_House_Price_Prediction_data.csv')"
      ],
      "metadata": {
        "id": "ToLGORy2wEAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "87mUW5-wwIrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Always remember there way always be a chance of data leakage so we need to split the data first and then apply feature\n",
        "## Engineering\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)"
      ],
      "metadata": {
        "id": "c4trTq3CwKfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "xOXHfNRiwORW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Missing Values#\n"
      ],
      "metadata": {
        "id": "nJYrWOQ5yZ5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Let us capture all the nan values\n",
        "## First lets handle Categorical features which are missing\n",
        "features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\n",
        "\n",
        "for feature in features_nan:\n",
        "    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))"
      ],
      "metadata": {
        "id": "0O_W7naGyZcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Replace missing value with a new label\n",
        "def replace_cat_feature(dataset,features_nan):\n",
        "  data=dataset.copy()\n",
        "  data[features_nan]=data[features_nan].fillna(\"Missing\")\n",
        "  return data\n",
        "\n",
        "dataset=replace_cat_feature(dataset,features_nan)\n",
        "dataset[features_nan].isnull().sum()"
      ],
      "metadata": {
        "id": "LLI9ezNVy_qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "p5Ei31eWy_nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now lets check for numerical variables the contains missing values\n",
        "numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n",
        "\n",
        "## We will print the numerical nan variables and percentage of missing values\n",
        "\n",
        "for feature in numerical_with_nan:\n",
        "    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))"
      ],
      "metadata": {
        "id": "c-BdzAif1tNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the numerical missing values\n",
        "for feature in numerical_with_nan:\n",
        "  #we will print the numerical nan variables and percentage of missing values\n",
        "  median_value=dataset[feature].median()\n",
        "\n",
        "  #create a new feature to compare nan values\n",
        "  dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n",
        "  dataset[feature].fillna(median_value,inplace=True)\n",
        "\n",
        "dataset[numerical_with_nan].isnull().sum()"
      ],
      "metadata": {
        "id": "cr65dAsPXBGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(50)"
      ],
      "metadata": {
        "id": "WQ-1BHiEXTGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Temporal Variables"
      ],
      "metadata": {
        "id": "hoCWTmiEY6vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Temporal Variables (Date Time Variables)\n",
        "\n",
        "for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n",
        "    dataset[feature]=dataset['YrSold']-dataset[feature]"
      ],
      "metadata": {
        "id": "dk-Z-TDUZa2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "9xLEy5cTY6Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()"
      ],
      "metadata": {
        "id": "YrA2dhHKaA9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Numerical Variables"
      ],
      "metadata": {
        "id": "ekmBAdM0aFHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Since the numerical variables are skewed we will perform log normal distribution\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "mmYdhxgbaEKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
        "\n",
        "for feature in num_features:\n",
        "    dataset[feature]=np.log(dataset[feature])"
      ],
      "metadata": {
        "id": "SuyQMI0Ze8Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "RjAZz97he_-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Rare Categorical Value\n",
        "\n",
        "We will remove categorical variables that are present less than 1% of the observations"
      ],
      "metadata": {
        "id": "pny9-ljzfcQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']"
      ],
      "metadata": {
        "id": "CDtrkxdufhbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features"
      ],
      "metadata": {
        "id": "JRR3q3N6fkqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in categorical_features:\n",
        "  temp=dataset.groupby(feature)['SalePrice'].count()/len(dataset)\n",
        "  temp_df=temp[temp>0.01].index\n",
        "  dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6Wlxao4fp7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(100)\n"
      ],
      "metadata": {
        "id": "5MFrOogwfvE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.groupby(['MSZoning'])['SalePrice'].mean()"
      ],
      "metadata": {
        "id": "NC2xR9fMhEb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Scaling"
      ],
      "metadata": {
        "id": "rWrF-w3JhtYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePerice'] ]"
      ],
      "metadata": {
        "id": "R1IytwtGiEJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataset[feature_scale])"
      ],
      "metadata": {
        "id": "Rl_Qil--hdJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.transform(dataset[feature_scale])"
      ],
      "metadata": {
        "id": "2HVmAKTfjmMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform the train and test set, and add on the Id and SalePrice variables\n",
        "data = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n",
        "                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n",
        "                    axis=1)"
      ],
      "metadata": {
        "id": "7FyZ7DCCiudH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "onUNzR8Oj4jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('X_train.csv',index=False)"
      ],
      "metadata": {
        "id": "Mz_jL99Yj_ZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}